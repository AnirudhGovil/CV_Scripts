{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib qt \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdown_points = np.loadtxt('topdown1_undistorted_image_points_2D.txt')\n",
    "fronton_points = np.loadtxt('fronton1_undistorted_image_points_2D.txt')\n",
    "world_points = np.loadtxt('world_points_3D.txt')\n",
    "topdown_camera = np.loadtxt('topdown1_new_camera_matrix.txt')\n",
    "fronton_camera = np.loadtxt('fronton1_new_camera_matrix.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays of type float32\n",
    "topdown_points = np.array(topdown_points, dtype=np.float32)\n",
    "fronton_points = np.array(fronton_points, dtype=np.float32)\n",
    "world_points = np.array(world_points, dtype=np.float32)\n",
    "topdown_camera = np.array(topdown_camera, dtype=np.float32)\n",
    "fronton_camera = np.array(fronton_camera, dtype=np.float32)\n",
    "\n",
    "# Use cv.solvePnP to find the rotation and translation vectors.\n",
    "\n",
    "def get_rotation_and_translation_vectors(world_points, image_points, camera_matrix):\n",
    "    \"\"\"\n",
    "    Returns the rotation and translation vectors for the given world and image points.\n",
    "    :param world_points: The world points.\n",
    "    :param image_points: The image points.\n",
    "    :param camera_matrix: The camera matrix.\n",
    "    :return: The rotation and translation vectors.\n",
    "    \"\"\"\n",
    "    _, rvec, tvec = cv2.solvePnP(world_points, image_points, camera_matrix, None)\n",
    "    # Since rvec is a rotation vector, we need to convert it to a rotation matrix.\n",
    "    rmat, _ = cv2.Rodrigues(rvec)\n",
    "    return rmat, tvec, rvec\n",
    "\n",
    "topdown_rmat, topdown_tvec, topdown_rvec = get_rotation_and_translation_vectors(world_points, topdown_points, topdown_camera)\n",
    "fronton_rmat, fronton_tvec, fronton_rvec = get_rotation_and_translation_vectors(world_points, fronton_points, fronton_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation(camera1_coords, camera1_M, camera1_R, camera1_T, camera2_coords, camera2_M, camera2_R, camera2_T):\n",
    "    \"\"\"\n",
    "    This function takes in a set of 2 points from 2 different cameras and finds the original point\n",
    "    : param camera1_coords: A tuple of the (u,v) coordinates of the point in camera 1\n",
    "    : param camera1_M: The camera matrix of camera 1\n",
    "    : param camera1_R: The rotation vector of camera 1\n",
    "    : param camera1_T: The translation vector of camera 1\n",
    "    : param camera2_coords: A tuple of the (u,v) coordinates of the point in camera 2\n",
    "    : param camera2_M: The camera matrix of camera 2\n",
    "    : param camera2_R: The rotation vector of camera 2\n",
    "    : param camera2_T: The translation vector of camera 2\n",
    "    : return: The (x,y,z) coordinates of the original point\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the two key equations from camera1\n",
    "    camera1_u, camera1_v = camera1_coords\n",
    "    # Put the rotation and translation side by side and then multiply with camera matrix\n",
    "    camera1_P = camera1_M.dot(np.column_stack((camera1_R,camera1_T)))\n",
    "    # Get the two linearly independent equation referenced in the notes\n",
    "    camera1_vect1 = camera1_v*camera1_P[2,:]-camera1_P[1,:]\n",
    "    camera1_vect2 = camera1_P[0,:] - camera1_u*camera1_P[2,:]\n",
    "    \n",
    "    # Get the two key equations from camera2\n",
    "    camera2_u, camera2_v = camera2_coords\n",
    "    # Put the rotation and translation side by side and then multiply with camera matrix\n",
    "    camera2_P = camera2_M.dot(np.column_stack((camera2_R,camera2_T)))\n",
    "    # Get the two linearly independent equation referenced in the notes\n",
    "    camera2_vect1 = camera2_v*camera2_P[2,:]-camera2_P[1,:]\n",
    "    camera2_vect2 = camera2_P[0,:] - camera2_u*camera2_P[2,:]\n",
    "    \n",
    "    # Stack the 4 rows to create one 4x3 matrix\n",
    "    full_matrix = np.row_stack((camera1_vect1, camera1_vect2, camera2_vect1, camera2_vect2))\n",
    "    # The first three columns make up A and the last column is b\n",
    "    A = full_matrix[:, :3]\n",
    "    b = full_matrix[:, 3].reshape((4, 1))\n",
    "    # Solve overdetermined system. The solution is the point in 3D space\n",
    "    soln = np.linalg.inv(A.T.dot(A)).dot(A.T).dot(-b)\n",
    "    return soln\n",
    "\n",
    "triangulated_points = []\n",
    "for i in range(len(topdown_points)):\n",
    "    triangulated_points.append(triangulation(topdown_points[i], topdown_camera, topdown_rmat, topdown_tvec, fronton_points[i], fronton_camera, fronton_rmat, fronton_tvec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triangulation error: 0.03228534796266908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get triangulation error\n",
    "\n",
    "def get_triangulation_error(triangulated_points, world_points):\n",
    "    \"\"\"\n",
    "    Returns the triangulation error.\n",
    "    :param triangulated_points: The triangulated points.\n",
    "    :param world_points: The world points.\n",
    "    :return: The triangulation error.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(triangulated_points[:,:,0] - world_points, axis=1).mean()\n",
    "\n",
    "print('Triangulation error: {}'.format(get_triangulation_error(np.array(triangulated_points), world_points)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the triangulated points\n",
    "\n",
    "def visualize_triangulated_points(triangulated_points, world_points):\n",
    "    \"\"\"\n",
    "    Visualizes the triangulated points.\n",
    "    :param triangulated_points: The triangulated points.\n",
    "    :param world_points: The world points.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20,20),dpi=100)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    X = np.array(triangulated_points)[:,0]\n",
    "    Y = np.array(triangulated_points)[:,1]\n",
    "    Z = np.array(triangulated_points)[:,2]\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    ax.scatter3D(world_points[:,0], world_points[:,1], world_points[:,2], c='g', label='World Points')\n",
    "    ax.scatter3D(X, Y, Z, c='r', label='Triangulated Points')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_triangulated_points(triangulated_points, world_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select new points to triangulate\n",
    "\n",
    "imgpath = 'topdown1.png'\n",
    "img = cv2.imread(imgpath)\n",
    "topdown_image_points = []\n",
    "fig = plt.figure(figsize=(80,120))\n",
    "\n",
    "img = mpimg.imread(imgpath)\n",
    "\n",
    "def onclick(event):\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    topdown_image_points.append([ix, iy])\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This cell displays the points you have clicked.\n",
    "N = len(topdown_image_points)\n",
    "topdown_image_points = np.array(topdown_image_points)\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "img = mpimg.imread(imgpath)\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "colors = np.random.rand(N)\n",
    "area = (30 * np.ones(N))**2 \n",
    "\n",
    "plt.scatter(topdown_image_points[:,0], topdown_image_points[:,1], c=colors, s=area)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = 'fronton1.png'\n",
    "img = cv2.imread(imgpath)\n",
    "fronton_image_points = []\n",
    "fig = plt.figure(figsize=(80,120))\n",
    "\n",
    "img = mpimg.imread(imgpath)\n",
    "\n",
    "def onclick(event):\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    fronton_image_points.append([ix, iy])\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(fronton_image_points)\n",
    "fronton_image_points = np.array(fronton_image_points)\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "img = mpimg.imread(imgpath)\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "colors = np.random.rand(N)\n",
    "area = (30 * np.ones(N))**2 \n",
    "\n",
    "plt.scatter(fronton_image_points[:,0], fronton_image_points[:,1], c=colors, s=area)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Triangulation error: 6.444040643908214\n"
     ]
    }
   ],
   "source": [
    "# Dewarp both points\n",
    "\n",
    "topdown_old_camera = np.loadtxt('topdown1_camera_matrix.txt')\n",
    "fronton_old_camera = np.loadtxt('fronton1_camera_matrix.txt')\n",
    "topdown_distortion = np.loadtxt('topdown1_distortion_coefficients.txt')\n",
    "fronton_distortion = np.loadtxt('fronton1_distortion_coefficients.txt')\n",
    "\n",
    "dewarped_topdown_image_points = cv2.undistortPoints(np.array([topdown_image_points]), topdown_old_camera, topdown_distortion, P=topdown_camera).reshape(-1,2)\n",
    "dewarped_fronton_image_points = cv2.undistortPoints(np.array([fronton_image_points]), fronton_old_camera, fronton_distortion, P=fronton_camera).reshape(-1,2)\n",
    "\n",
    "\n",
    "new_triangulated_points = []\n",
    "for i in range(len(topdown_image_points)):\n",
    "    new_triangulated_points.append(triangulation(dewarped_topdown_image_points[i], topdown_camera, topdown_rmat, topdown_tvec, dewarped_fronton_image_points[i], fronton_camera, fronton_rmat, fronton_tvec))\n",
    "\n",
    "# Visualize the new triangulated points\n",
    "NET_Y = 0.76 + 3.96 + 1.98\n",
    "NET_HEIGHT = 1.55\n",
    "RIGHT_BOUNDARY_X = 0.46 + 2.59 + 2.59 + 0.46\n",
    "new_world_points = np.array([[0 ,NET_Y, NET_HEIGHT],[ RIGHT_BOUNDARY_X,NET_Y ,NET_HEIGHT]])\n",
    "print(len(new_triangulated_points))\n",
    "visualize_triangulated_points(triangulated_points+new_triangulated_points, world_points)\n",
    "\n",
    "# Get the new triangulation error\n",
    "\n",
    "print('Triangulation error: {}'.format(get_triangulation_error(np.array(new_triangulated_points).T, world_points)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
