{"cells":[{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# import libraries\n","%matplotlib tk\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import matplotlib.cm as cm\n","import numpy as np\n","\n","imgpath = 'fronton1.png'\n","# imgpath = 'topdown1.png'\n","img = cv2.imread(imgpath)\n","\n","image_points = np.loadtxt(f'{imgpath[:-4]}_image_points_2D.txt')\n","# Convert to float32\n","image_points = np.array(image_points, dtype=np.float32)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# World Points\n","# Since the image is a badminton court, we can define the coordinates as follows\n","LEFT_BOUNDARY_X = 0\n","LEFT_SIDELINE_X = 0.46\n","CENTRE_LINE_X = 0.46 + 2.59\n","RIGHT_SIDELINE_X = 0.46 + 2.59 + 2.59\n","RIGHT_BOUNDARY_X = 0.46 + 2.59 + 2.59 + 0.46\n","BOTTOM_BOUNDARY_Y = 0\n","BOTTOM_LONG_SERVICE_LINE  = 0.76\n","BOTTOM_SHORT_SERVICE_LINE = 0.76 + 3.96\n","NET_Y = 0.76 + 3.96 + 1.98\n","NET_HEIGHT = 1.55\n","TOP_SHORT_SERVICE_LINE = 0.76 + 3.96 + 3.96\n","TOP_LONG_SERVICE_LINE = 0.76 + 3.96 + 3.96 + 3.96\n","TOP_BOUNDARY_Y = 0.76 + 3.96 + 3.96 + 3.96 + 0.76\n","\n","# Selected points gt\n","objp = np.zeros((1, 32, 3), np.float32)\n","\n","objp[0, 0:5, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 0:5, 1] = np.ones(5) * BOTTOM_BOUNDARY_Y\n","objp[0, 0:5, 2] = [0, 0, 0, 0, 0]\n","objp[0, 5:10, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 5:10, 1] = np.ones(5) * BOTTOM_LONG_SERVICE_LINE\n","objp[0, 5:10, 2] = [0, 0, 0, 0, 0]\n","objp[0, 10:15, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 10:15, 1] = np.ones(5) * BOTTOM_SHORT_SERVICE_LINE\n","objp[0, 10:15, 2] = [0, 0, 0, 0, 0]\n","objp[0, 15:17, 0] = [LEFT_BOUNDARY_X, RIGHT_BOUNDARY_X]\n","objp[0, 15:17, 1] = np.ones(2) * NET_Y\n","objp[0, 15:17, 2] = [0, 0] \n","objp[0, 17:22, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 17:22, 1] = np.ones(5) * TOP_SHORT_SERVICE_LINE\n","objp[0, 17:22, 2] = [0, 0, 0, 0, 0]\n","objp[0, 22:27, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 22:27, 1] = np.ones(5) * TOP_LONG_SERVICE_LINE\n","objp[0, 22:27, 2] = [0, 0, 0, 0, 0]\n","objp[0, 27:32, 0] = [LEFT_BOUNDARY_X,LEFT_SIDELINE_X, CENTRE_LINE_X, RIGHT_SIDELINE_X, RIGHT_BOUNDARY_X]\n","objp[0, 27:32, 1] = np.ones(5) * TOP_BOUNDARY_Y\n","objp[0, 27:32, 2] = [0, 0, 0, 0, 0]\n","\n","world_points = objp[0]\n","\n","# Save world points\n","np.savetxt('world_points_3D.txt', world_points)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["\n","world_points_temp = []\n","image_points_temp = []\n","world_points_temp.append(world_points)\n","image_points_temp.append(image_points)\n","\n","ret, camera_matrix, distortion_coefficients, rotation_vectors, translation_vectors = cv2.calibrateCamera(world_points_temp, image_points_temp, (img.shape[1], img.shape[0]), None, None)\n","\n","# Check Reprojection Error\n","mean_error = 0\n","for i in range(len(world_points_temp)):\n","    imgpoints2, _ = cv2.projectPoints(world_points_temp[i], rotation_vectors[i], translation_vectors[i], camera_matrix, distortion_coefficients)\n","\n","# Visualize\n","img = cv2.imread(imgpath)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(20,20),dpi=100)\n","plt.scatter(imgpoints2[:,0,0], imgpoints2[:,0,1], c='r', s=100)\n","plt.imshow(img)\n","plt.show()\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["camera_matrix: [[1.13918437e+03 0.00000000e+00 7.92821860e+02]\n"," [0.00000000e+00 1.18346621e+03 1.23328737e+03]\n"," [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n","distortion_coefficients: [[-0.32281444  0.21812507 -0.05371257 -0.00114272 -0.05419283]]\n","rotation_vectors: (array([[ 2.26557185],\n","       [ 0.02385197],\n","       [-0.02439056]]),)\n","new_camera_matrix: [[782.92565918   0.         740.55012595]\n"," [  0.         876.03704834 908.622262  ]\n"," [  0.           0.           1.        ]]\n","roi: (196, 10, 1186, 1563)\n"]}],"source":["\n","\n","distortion_params = distortion_coefficients.ravel()\n","\n","print(f'camera_matrix: {camera_matrix}')\n","print(f'distortion_coefficients: {distortion_coefficients}')\n","print(f'rotation_vectors: {rotation_vectors}')\n","\n","new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, distortion_coefficients, (img.shape[1], img.shape[0]), 1, (img.shape[1], img.shape[0]))\n","\n","print(f'new_camera_matrix: {new_camera_matrix}')\n","print(f'roi: {roi}')\n","\n","undistorted_img = cv2.undistort(img, camera_matrix, distortion_coefficients, None, new_camera_matrix)\n","\n","# crop the image\n","x, y, w, h = roi\n","# x-=75\n","# w+=115\n","# y-=15\n","# h+=30\n","\n","undistorted_img_cropped = undistorted_img[y:y+h, x:x+w]\n","plt.figure(figsize=(20,20),dpi=100)\n","plt.imshow(undistorted_img_cropped)\n","plt.show()\n","\n","# Save the 3x3 camera matrix\n","\n","np.savetxt(f'{imgpath[:-4]}_camera_matrix.txt', camera_matrix)\n","\n","# Save the 3x3 new camera matrix\n","\n","np.savetxt(f'{imgpath[:-4]}_new_camera_matrix.txt', new_camera_matrix)\n","\n","# Save the distortion coefficients\n","\n","np.savetxt(f'{imgpath[:-4]}_distortion_coefficients.txt', distortion_coefficients)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Get the undistorted image points\n","\n","undistorted_image_points = cv2.undistortPoints(image_points, camera_matrix, distortion_coefficients, None, new_camera_matrix)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Plot the undistorted image points on the undistorted image\n","undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(20,20),dpi=100)\n","plt.scatter(undistorted_image_points[:,0,0], undistorted_image_points[:,0,1], c='r', s=100)\n","plt.imshow(undistorted_img)\n","plt.show()\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# Save the pixel coordinates of the undistorted image points\n","np.savetxt(f'{imgpath[:-4]}_undistorted_image_points_2D.txt', undistorted_image_points[:,0,:])"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def create_projection_matrix(rotation_vectors, translation_vectors, camera_matrix):\n","    \"\"\"\n","    Create the 3x4 projection matrix\n","    :param rotation_vectors: rotation vectors\n","    :param translation_vectors: translation vectors\n","    :param camera_matrix: camera matrix\n","    \"\"\"\n","    R = cv2.Rodrigues(rotation_vectors[0])[0]\n","    t = translation_vectors[0]\n","    Rt = np.concatenate([R,t], axis=-1) # [R|t]\n","    P = np.matmul(camera_matrix,Rt) # A[R|t]\n","    return P\n","\n","P = create_projection_matrix(rotation_vectors, translation_vectors, new_camera_matrix)\n","\n","# Visualize the 3D points using the projection matrix\n","homogeneous_world_points = np.concatenate([world_points, np.ones((world_points.shape[0],1))], axis=-1)\n","homogeneous_image_points = np.matmul(P, homogeneous_world_points.T).T\n","image_points = homogeneous_image_points[:,0:2] / homogeneous_image_points[:,2:3]\n","plt.figure(figsize=(20,20),dpi=100)\n","plt.scatter(image_points[:,0], image_points[:,1], c='r', s=10)\n","plt.imshow(undistorted_img)\n","plt.show()\n","\n","# Save the 3x4 projection matrix\n","\n","np.savetxt(f'{imgpath[:-4]}_projection_matrix.txt', P)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"cv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
